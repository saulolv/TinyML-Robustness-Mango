{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846de747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:12:06.710706: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-13 13:12:06.714931: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 13:12:06.763321: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 13:12:06.817365: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749831126.868323   76749 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749831126.883184   76749 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749831126.986230   76749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749831126.986263   76749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749831126.986265   76749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749831126.986266   76749 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-13 13:12:06.997553: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import MaxPooling2D, Flatten, Dense,BatchNormalization,GlobalAveragePooling2D,Conv2D,Dropout,Flatten,Rescaling,Input\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61e6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"MangoLeaf\"\n",
    "img_size = (224,224)\n",
    "batch_size = 32\n",
    "mode = \"rgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd16f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1749831534.989864   76749 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1749831534.990302   76749 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"models/efficientNetB0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brightness severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 600ms/step\n",
      "Brightness severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 611ms/step\n",
      "Brightness severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 592ms/step\n",
      "Brightness severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 544ms/step\n",
      "Brightness severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 527ms/step\n",
      "Contrast severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 581ms/step\n",
      "Contrast severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 606ms/step\n",
      "Contrast severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 521ms/step\n",
      "Contrast severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 570ms/step\n",
      "Contrast severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 620ms/step\n",
      "Defocus Blur severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 673ms/step\n",
      "Defocus Blur severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 696ms/step\n",
      "Defocus Blur severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 593ms/step\n",
      "Defocus Blur severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 662ms/step\n",
      "Defocus Blur severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 627ms/step\n",
      "Elastic severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 641ms/step\n",
      "Elastic severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 626ms/step\n",
      "Elastic severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 591ms/step\n",
      "Elastic severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 567ms/step\n",
      "Elastic severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 626ms/step\n",
      "Fog severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 636ms/step\n",
      "Fog severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step\n",
      "Fog severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 766ms/step\n",
      "Fog severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 932ms/step\n",
      "Fog severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 978ms/step\n",
      "Frost severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 501ms/step\n",
      "Frost severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 491ms/step\n",
      "Frost severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 645ms/step\n",
      "Frost severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step\n",
      "Frost severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 891ms/step\n",
      "Gaussian Blur severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step\n",
      "Gaussian Blur severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step\n",
      "Gaussian Blur severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step\n",
      "Gaussian Blur severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step\n",
      "Gaussian Blur severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step\n",
      "Gaussian Noise severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step\n",
      "Gaussian Noise severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step\n",
      "Gaussian Noise severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step\n",
      "Gaussian Noise severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 2s/step\n",
      "Gaussian Noise severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step\n",
      "Glass Blur severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step\n",
      "Glass Blur severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 2s/step\n",
      "Glass Blur severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 2s/step\n",
      "Glass Blur severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step\n",
      "Glass Blur severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 1s/step\n",
      "Impulse Noise severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step\n",
      "Impulse Noise severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 851ms/step\n",
      "Impulse Noise severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 716ms/step\n",
      "Impulse Noise severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 707ms/step\n",
      "Impulse Noise severity 5\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 719ms/step\n",
      "JPEG severity 1\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step\n",
      "JPEG severity 2\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step\n",
      "JPEG severity 3\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step\n",
      "JPEG severity 4\n",
      "Found 4000 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saulolv/PIBIC/TinyML/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning:\n",
      "\n",
      "Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/125\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 2s/step"
     ]
    }
   ],
   "source": [
    "# Função para processar e avaliar cada banco corrompido\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "def funcaoParaObterAcuraciaParaMultiClasses(verdade, predicao, numeroDeClasses, ImagensPorClasse):\n",
    "    \n",
    "    vetorAuxiliar = [0 for _ in range(numeroDeClasses)]\n",
    "\n",
    "    for i in range(0, len(predicao)):\n",
    "        if verdade[i] == predicao[i]:\n",
    "            vetorAuxiliar[verdade[i]] = vetorAuxiliar[(verdade[i])] + 1\n",
    "\n",
    "    vetorDeAcuracia = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "        \n",
    "    for i in range(0, len(vetorAuxiliar)):\n",
    "        vetorDeAcuracia[i] = vetorAuxiliar[i]/ImagensPorClasse\n",
    "        \n",
    "    return vetorDeAcuracia\n",
    "\n",
    "\n",
    "\n",
    "def df_maker(path):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "\n",
    "    # Listando as pastas dentro do diretório base (representam as classes)\n",
    "    folds = os.listdir(path)\n",
    "    for fold in folds:\n",
    "        fold_path = os.path.join(path, fold)\n",
    "        file_list = os.listdir(fold_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(fold_path, file)\n",
    "            file_paths.append(file_path)\n",
    "            labels.append(fold)\n",
    "\n",
    "    # Criando uma série para caminhos e rótulos\n",
    "    file_series = pd.Series(file_paths, name=\"file_paths\")\n",
    "    label_series = pd.Series(labels, name=\"labels\")\n",
    "\n",
    "    # Concatenando as séries para formar um dataframe\n",
    "    df = pd.concat([file_series, label_series], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_corrupted_model(model, corrupted_data_path, corruption_name):\n",
    "    # Cria o dataframe com o caminho das imagens e rótulos\n",
    "    corrupted_df = df_maker(corrupted_data_path)\n",
    "    \n",
    "    # Cria o generator para o banco corrompido\n",
    "    corrupted_datagen = ImageDataGenerator()\n",
    "    corrupted_data = corrupted_datagen.flow_from_dataframe(\n",
    "        corrupted_df,\n",
    "        x_col=\"file_paths\",\n",
    "        y_col=\"labels\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=mode,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # Realiza as predições\n",
    "    predictions = model.predict(corrupted_data)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = corrupted_data.classes\n",
    "\n",
    "    # Calcula e coleta métricas\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division = 0)\n",
    "    report['corruption'] = corruption_name  # Adiciona o nome da corrupção para referência\n",
    "    \n",
    "    acuraciaPorClasse = funcaoParaObterAcuraciaParaMultiClasses(y_true, y_pred, 8, ImagensPorClasse=500)\n",
    "\n",
    "    report['acuraciaPorClasse'] = acuraciaPorClasse\n",
    "    \n",
    "    return report\n",
    "\n",
    "base_path = \"../../bancos\"\n",
    "\n",
    "corruption_types = [\n",
    "    \"Brightness\", \"Contrast\", \"Defocus Blur\", \"Elastic\", \"Fog\",\n",
    "    \"Frost\", \"Gaussian Blur\", \"Gaussian Noise\", \"Glass Blur\",\n",
    "    \"Impulse Noise\", \"JPEG\", \"Motion Blur\", \"Pixelate\", \"Saturate\",\n",
    "    \"Shot Noise\", \"Snow\", \"Spatter\", \"Speckle Noise\", \"Zoom Blur\"\n",
    "]\n",
    "\n",
    "severities = [1, 2, 3, 4, 5]\n",
    "\n",
    "corrupted_paths = [\n",
    "    os.path.join(base_path, f\"{corruption}_severity_{severity}\")\n",
    "    for corruption in corruption_types\n",
    "    for severity in severities\n",
    "]\n",
    "\n",
    "# Avaliação de todos os bancos\n",
    "results = []\n",
    "# Validar caminhos\n",
    "for path in corrupted_paths:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Aviso: O caminho {path} não existe e será ignorado.\")\n",
    "        continue\n",
    "    corruption_name = os.path.basename(path).replace(\"_\", \" \")\n",
    "    print(corruption_name)\n",
    "    report = evaluate_corrupted_model(model, path, corruption_name)\n",
    "    results.append(report)\n",
    "\n",
    "\n",
    "# Criar e salvar DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results/results_efficientNetB0.csv\", index=False)\n",
    "\n",
    "print(\"ok\")\n",
    "\n",
    "\n",
    "# # Cria o DataFrame com os resultados para visualização\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../../v2/results/results_efficientNetB0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e641d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Convert from .csv to .xlsx\n",
    "df = pd.read_csv(\"../../v2/results/results_efficientNetB0.csv\")\n",
    "df.to_excel(\"../../v2/results/results_efficientNetB0_forEach_corruption.xlsx\", index=False)\n",
    "\n",
    "# Caminho do arquivo .xlsx\n",
    "# caminho_arquivo = r\"C:\\projeto\\resultadosDalccnParaCadaBancoModeloEscolhido.xlsx\"\n",
    "archive_path = \"../../v2/results/results_efficientNetB0_forEach_corruption.xlsx\"\n",
    "\n",
    "# Nome das colunas que você deseja extrair\n",
    "colunas_desejadas = ['macro avg', 'accuracy', 'corruption']\n",
    "\n",
    "# Ler o arquivo Excel e selecionar as colunas desejadas\n",
    "df = pd.read_excel(archive_path, usecols=colunas_desejadas)\n",
    "\n",
    "# Exibir o DataFrame com as colunas selecionadas\n",
    "print(\"DataFrame inicial:\")\n",
    "print(df)\n",
    "\n",
    "# Inicializar variáveis para somar os valores\n",
    "somaPrecision = 0\n",
    "somaRecall = 0\n",
    "somaF1Score = 0\n",
    "somaAcuracia = 0\n",
    "\n",
    "# Criar um novo DataFrame para armazenar os resultados\n",
    "novodf = pd.DataFrame(columns=['precision', 'recall', 'f1-score', 'corruption', 'acuracia'])\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        # Converter a string da coluna 'macro avg' em um dicionário\n",
    "        dicionario = ast.literal_eval(row['macro avg'])\n",
    "        \n",
    "        # Somar os valores\n",
    "        somaPrecision += dicionario['precision']\n",
    "        somaRecall += dicionario['recall']\n",
    "        somaF1Score += dicionario['f1-score']\n",
    "        somaAcuracia += row['accuracy']\n",
    "        \n",
    "        # Adicionar uma nova linha ao novo DataFrame\n",
    "        novalinha = {\n",
    "            'precision': dicionario['precision'],\n",
    "            'recall': dicionario['recall'],\n",
    "            'f1-score': dicionario['f1-score'],\n",
    "            'corruption': row['corruption'],\n",
    "            'acuracia': row['accuracy']\n",
    "        }\n",
    "        \n",
    "        # Usar pd.concat para adicionar a nova linha\n",
    "        novodf = pd.concat([novodf, pd.DataFrame([novalinha])], ignore_index=True)\n",
    "    \n",
    "    except (ValueError, SyntaxError):\n",
    "        # Caso ocorra um erro ao converter a string para dicionário\n",
    "        print(f\"Erro ao processar a linha {index}: {row['macro avg']}\")\n",
    "        continue\n",
    "\n",
    "# Calcular as médias\n",
    "total_linhas = len(df)\n",
    "if total_linhas > 0:\n",
    "    mediaPrecision = somaPrecision / total_linhas\n",
    "    mediaRecall = somaRecall / total_linhas\n",
    "    mediaF1Score = somaF1Score / total_linhas\n",
    "else:\n",
    "    mediaPrecision = mediaRecall = mediaF1Score = 0\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\nResultado Geral:\")\n",
    "print(f\"Precision: {mediaPrecision}\")\n",
    "print(f\"Recall: {mediaRecall}\")\n",
    "print(f\"f1-score: {mediaF1Score}\")\n",
    "print(f\"Acuracia: {somaAcuracia}\")\n",
    "\n",
    "# Exibir o novo DataFrame\n",
    "print(\"\\nNovo DataFrame:\")\n",
    "print(novodf)\n",
    "\n",
    "# Salvar o novo DataFrame em um arquivo .xlsx\n",
    "output_path = \"../../v2/results/results_corrupted_data_efficientNetB0.xlsx\"\n",
    "novodf.to_excel(output_path, index=False)\n",
    "print(f\"DataFrame salvo com sucesso em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b499a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Caminho do arquivo .xlsx\n",
    "# caminho_arquivo = r\"C:\\projeto\\resultadosDalccnParaCadaBancoModeloEscolhido.xlsx\"\n",
    "archive_path = \"../../v2/results/results_efficientNetB0_forEach_corruption.xlsx\"\n",
    "\n",
    "# Nome das colunas que você deseja extrair\n",
    "colunas_desejadas = ['0', '1', '2', '3', '4', '5', '6', '7', 'acuraciaPorClasse']\n",
    "\n",
    "# Ler o arquivo Excel e selecionar as colunas desejadas\n",
    "df = pd.read_excel(archive_path, usecols=colunas_desejadas)\n",
    "\n",
    "# Exibir o DataFrame com as colunas selecionadas\n",
    "print(\"DataFrame inicial:\")\n",
    "print(df)\n",
    "\n",
    "# Inicializar os dicionários para cada classe\n",
    "Anthracnose = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "BacterialCanker = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "CuttingWeevil = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "DieBack = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "GallMidge = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "Healthy = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "PowderyMildew = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "SootyMould = {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'acuracia': 0.0}\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Converter a string da coluna 'macro avg' em um dicionário\n",
    "    classe0 = ast.literal_eval(row['0'])\n",
    "    classe1 = ast.literal_eval(row['1'])\n",
    "    classe2 = ast.literal_eval(row['2'])\n",
    "    classe3 = ast.literal_eval(row['3'])\n",
    "    classe4 = ast.literal_eval(row['4'])\n",
    "    classe5 = ast.literal_eval(row['5'])\n",
    "    classe6 = ast.literal_eval(row['6'])\n",
    "    classe7 = ast.literal_eval(row['7'])\n",
    "    \n",
    "    # Converter a string da coluna 'acuraciaPorClasse' em uma lista\n",
    "    classe8 = ast.literal_eval(row['acuraciaPorClasse'])\n",
    "    \n",
    "    # Somar os valores para cada classe\n",
    "    Anthracnose['precision'] += classe0['precision']\n",
    "    Anthracnose['recall'] += classe0['recall']\n",
    "    Anthracnose['f1-score'] += classe0['f1-score']\n",
    "    Anthracnose['acuracia'] += float(classe8[0])  # Converter para float\n",
    "    \n",
    "    BacterialCanker['precision'] += classe1['precision']\n",
    "    BacterialCanker['recall'] += classe1['recall']\n",
    "    BacterialCanker['f1-score'] += classe1['f1-score']\n",
    "    BacterialCanker['acuracia'] += float(classe8[1])  # Converter para float\n",
    "    \n",
    "    CuttingWeevil['precision'] += classe2['precision']\n",
    "    CuttingWeevil['recall'] += classe2['recall']\n",
    "    CuttingWeevil['f1-score'] += classe2['f1-score']\n",
    "    CuttingWeevil['acuracia'] += float(classe8[2])  # Converter para float\n",
    "    \n",
    "    DieBack['precision'] += classe3['precision']\n",
    "    DieBack['recall'] += classe3['recall']\n",
    "    DieBack['f1-score'] += classe3['f1-score']\n",
    "    DieBack['acuracia'] += float(classe8[3])  # Converter para float\n",
    "    \n",
    "    GallMidge['precision'] += classe4['precision']\n",
    "    GallMidge['recall'] += classe4['recall']\n",
    "    GallMidge['f1-score'] += classe4['f1-score']\n",
    "    GallMidge['acuracia'] += float(classe8[4])  # Converter para float\n",
    "    \n",
    "    Healthy['precision'] += classe5['precision']\n",
    "    Healthy['recall'] += classe5['recall']\n",
    "    Healthy['f1-score'] += classe5['f1-score']\n",
    "    Healthy['acuracia'] += float(classe8[5])  # Converter para float\n",
    "    \n",
    "    PowderyMildew['precision'] += classe6['precision']\n",
    "    PowderyMildew['recall'] += classe6['recall']\n",
    "    PowderyMildew['f1-score'] += classe6['f1-score']\n",
    "    PowderyMildew['acuracia'] += float(classe8[6])  # Converter para float\n",
    "    \n",
    "    SootyMould['precision'] += classe7['precision']\n",
    "    SootyMould['recall'] += classe7['recall']\n",
    "    SootyMould['f1-score'] += classe7['f1-score']\n",
    "    SootyMould['acuracia'] += float(classe8[7])  # Converter para float\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "resultados = pd.DataFrame([Anthracnose, BacterialCanker, CuttingWeevil, DieBack, GallMidge, Healthy, PowderyMildew, SootyMould])\n",
    "\n",
    "# Dividir cada valor do DataFrame por 95\n",
    "resultados = resultados / 95\n",
    "\n",
    "# Exibir o DataFrame com os resultados\n",
    "print(\"DataFrame com os resultados (dividido por 95):\")\n",
    "print(resultados)\n",
    "\n",
    "# Exportar o DataFrame para um arquivo Excel\n",
    "# caminho_saida = r\"C:\\projeto\\resultados_classes_lcnnModeloEscolhido.xlsx\"\n",
    "caminho_saida = \"../../v2/results/resultados_classes_efficientNetB0.xlsx\"\n",
    "resultados.to_excel(caminho_saida, index=False)\n",
    "\n",
    "print(f\"Os resultados foram exportados para o arquivo: {caminho_saida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Caminho do arquivo .xlsx\n",
    "# caminho_arquivo = r\"C:/Users/DESKTOP/pesquisaGabriel/resultadosDasRedes/resultado_final_geral_bancosCorrompidos_ResNet50ModeloEscolhido.xlsx\"\n",
    "archive_path = \"../../v2/results/results_corrupted_data_efficientNetB0.xlsx\"\n",
    "\n",
    "# Nome das colunas que você deseja extrair\n",
    "colunas_desejadas = ['corruption', 'acuracia', 'f1-score']\n",
    "\n",
    "# Ler o arquivo Excel e selecionar as colunas desejadas\n",
    "df = pd.read_excel(archive_path, usecols=colunas_desejadas)\n",
    "\n",
    "# Criar um novo DataFrame vazio\n",
    "novodf = pd.DataFrame(columns=['corruption', 'somaDasAcuracia', 'qtdItens'])\n",
    "\n",
    "# Função para verificar se uma string já existe na coluna 'corruption'\n",
    "def verifica_corrupcao_existente(df, string):\n",
    "    return string in df['corruption'].values\n",
    "\n",
    "def get_prefix_before_severity(text):\n",
    "    parts = text.split(\"severity\", 1)\n",
    "    return parts[0].strip()\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    string = get_prefix_before_severity(row['corruption'])\n",
    "    if verifica_corrupcao_existente(novodf, string):\n",
    "        novodf.loc[novodf['corruption'] == string, 'somaDasAcuracia'] += row['acuracia']\n",
    "        novodf.loc[novodf['corruption'] == string, 'qtdItens'] += 1\n",
    "    else:\n",
    "        nova_linha = pd.DataFrame({'corruption': [string], 'somaDasAcuracia': [row['acuracia']], 'qtdItens': [1]})\n",
    "        novodf = pd.concat([novodf, nova_linha], ignore_index=True)\n",
    "\n",
    "# Criar um novo DataFrame para as médias\n",
    "novodf2 = pd.DataFrame(columns=['corruption', 'acuraciaMediaDasCorrupcoes'])\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame\n",
    "for index, row in novodf.iterrows():\n",
    "    nova_linha = pd.DataFrame({'corruption': [row['corruption']], 'acuraciaMediaDasCorrupcoes': [row['somaDasAcuracia'] / row['qtdItens']]})\n",
    "    novodf2 = pd.concat([novodf2, nova_linha], ignore_index=True)\n",
    "\n",
    "# Ordenar o DataFrame pela coluna 'acuraciaMediaDasCorrupcoes' em ordem decrescente\n",
    "novodf2 = novodf2.sort_values(by='acuraciaMediaDasCorrupcoes', ascending=False)\n",
    "\n",
    "# Pegar as 3 melhores e as 3 piores corrupções\n",
    "top_3_melhores = novodf2.head(3)\n",
    "top_3_piores = novodf2.tail(3)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"\\n3 melhores corrupções:\")\n",
    "print(top_3_melhores)\n",
    "\n",
    "print(\"\\n3 piores corrupções:\")\n",
    "print(top_3_piores)\n",
    "\n",
    "# Criar um DataFrame para o gráfico\n",
    "novodf_grafico = pd.DataFrame(columns=['corruption', 'severidade', 'f1-score'])\n",
    "\n",
    "# Iterar sobre as linhas do DataFrame original\n",
    "for index, row in df.iterrows():\n",
    "    string = row['corruption']\n",
    "    parts = string.split()\n",
    "    corrupcao = ''\n",
    "    severidade = 0\n",
    "    if len(parts) == 3:\n",
    "        corrupcao = parts[0]\n",
    "        severidade = int(parts[2])\n",
    "    elif len(parts) == 4:\n",
    "        corrupcao = parts[0] + \" \" + parts[1]\n",
    "        severidade = int(parts[3])\n",
    "    novodf_grafico.loc[index] = [corrupcao, severidade, row['f1-score']]\n",
    "\n",
    "# Criar o gráfico\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Lista de cores únicas para as linhas\n",
    "cores = plt.cm.tab20.colors\n",
    "\n",
    "# Lista de estilos de linhas e marcadores\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "markers = ['o', '^', 's', 'D']\n",
    "\n",
    "# Dicionário para mapear cada corrupção a uma cor única\n",
    "cor_mapping = {}\n",
    "cor_index = 0\n",
    "\n",
    "# Agrupar os dados por corrupção\n",
    "for i, (name, group) in enumerate(novodf_grafico.groupby('corruption')):\n",
    "    group = group.sort_values(by='severidade')\n",
    "    if name not in cor_mapping:\n",
    "        cor_mapping[name] = cores[cor_index]\n",
    "        cor_index = (cor_index + 1) % len(cores)\n",
    "    linestyle = linestyles[i % len(linestyles)]\n",
    "    marker = markers[i % len(markers)]\n",
    "    plt.plot(group['severidade'], group['f1-score'], marker=marker, linestyle=linestyle, label=name, color=cor_mapping[name])\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "plt.xlabel('Severidade')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('LCNN - Desempenho por Corrupção (Top3 e Bottom3 destacados)')\n",
    "\n",
    "# Definir os ticks do eixo x como 1, 2, 3, 4, 5\n",
    "plt.xticks([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Adicionar mais ticks no eixo y\n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2])\n",
    "\n",
    "# Adicionar a legenda embaixo do gráfico\n",
    "legenda = plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "\n",
    "# Lista para armazenar as anotações\n",
    "annotations = []\n",
    "\n",
    "# Adicionar anotações para as 3 melhores corrupções (Top1, Top2, Top3)\n",
    "for i, (index, row) in enumerate(top_3_melhores.iterrows(), start=1):\n",
    "    corrupcao = row['corruption']\n",
    "    media = row['acuraciaMediaDasCorrupcoes']\n",
    "    dados_corrupcao = novodf_grafico[novodf_grafico['corruption'] == corrupcao]\n",
    "    if not dados_corrupcao.empty:\n",
    "        severidade = dados_corrupcao['severidade'].max()\n",
    "        f1_score = dados_corrupcao[dados_corrupcao['severidade'] == severidade]['f1-score'].values[0]\n",
    "        annotations.append(plt.annotate(f'Top{i}: {corrupcao}\\navg: {media:.4f}', \n",
    "                                        xy=(severidade, f1_score), \n",
    "                                        xytext=(severidade + 0.2, f1_score - 0.05), \n",
    "                                        arrowprops=dict(facecolor='green', edgecolor='green', shrink=0.05, width = 0.4, headwidth = 8),\n",
    "                                        fontsize=9, color='green'))\n",
    "\n",
    "# Adicionar anotações para as 3 piores corrupções (Bottom1, Bottom2, Bottom3)\n",
    "for i, (index, row) in enumerate(top_3_piores.iterrows(), start=1):\n",
    "    corrupcao = row['corruption']\n",
    "    media = row['acuraciaMediaDasCorrupcoes']\n",
    "    dados_corrupcao = novodf_grafico[novodf_grafico['corruption'] == corrupcao]\n",
    "    if not dados_corrupcao.empty:\n",
    "        severidade = dados_corrupcao['severidade'].max()\n",
    "        f1_score = dados_corrupcao[dados_corrupcao['severidade'] == severidade]['f1-score'].values[0]\n",
    "        annotations.append(plt.annotate(f'Bottom{i}: {corrupcao}\\navg: {media:.4f}', \n",
    "                                        xy=(severidade, f1_score), \n",
    "                                        xytext=(severidade + 0.2, f1_score + 0.05), \n",
    "                                        arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, width = 0.4, headwidth = 8),\n",
    "                                        fontsize=9, color='red'))\n",
    "\n",
    "# Ajustar as anotações para evitar sobreposição\n",
    "adjust_text(annotations, \n",
    "            arrowprops=dict(arrowstyle='->', color='none'), \n",
    "            expand_points=(0.0, 0.0),  # Aumenta a distância entre as anotações\n",
    "            expand_text=(0.0, 0.0),    # Aumenta o espaço ao redor do texto\n",
    "            force_text=(-5, 2),     # Força o ajuste do texto\n",
    "            force_points=(0.00, 0.00))   # Força o ajuste dos pontos\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salvar o gráfico em um arquivo\n",
    "caminho_grafico = \"../../v2/results/grafico_efficientNetB0_corrupcoes.png\"\n",
    "plt.savefig(caminho_grafico, dpi=500, bbox_inches='tight')  # dpi=300 para alta qualidade\n",
    "print(f\"Gráfico salvo em: {caminho_grafico}\")\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
